{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70870c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (1020, 8)\n",
      "Columns in data: ['mid_price', 'ask_price', 'maturity', 'strike', 'implied_volatility', 'volume', 'expiration', 'moneyness']\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Tuple\n",
    "from scipy.optimize import minimize\n",
    "from datetime import datetime\n",
    "import bisect\n",
    "import warnings\n",
    "from scipy.integrate import quad, IntegrationWarning\n",
    "import functools\n",
    "import time\n",
    "from numba import njit, prange, float64, complex128\n",
    "\n",
    "# Suppress specific warnings from scipy.integrate.quad\n",
    "warnings.filterwarnings('ignore', category=UserWarning, message='The integral is probably divergent, or slowly convergent.')\n",
    "warnings.filterwarnings('ignore', category=IntegrationWarning)\n",
    "\n",
    "# Keep get_data_Calibration unchanged\n",
    "\n",
    "def get_data_Calibration(\n",
    "    symbol: str,\n",
    "    target_expiration: str,  # Format 'YYYY-MM-DD'\n",
    "    underlying_price: float,\n",
    ") -> pd.DataFrame:\n",
    "    try:\n",
    "        # Fixed tuple definitions - remove the trailing commas\n",
    "        min_volume: int = 5\n",
    "        max_spread_pct: float = 10.0\n",
    "        moneyness_range: Tuple[float, float] = (0.85, 1.15)\n",
    "        num_expirations: int = 8  # Number of expirations we want on each side\n",
    "        \n",
    "        ticker = yf.Ticker(symbol)\n",
    "        all_expirations = ticker.options\n",
    "        result = []\n",
    "\n",
    "        # Convert all expirations to datetime for comparison\n",
    "        expiration_dates = [pd.to_datetime(exp).date() for exp in all_expirations]\n",
    "        target_date = pd.to_datetime(target_expiration).date()\n",
    "        \n",
    "        # Find the index of the closest expiration to the target date\n",
    "        closest_idx = bisect.bisect_left(expiration_dates, target_date)\n",
    "        if closest_idx >= len(expiration_dates):\n",
    "            closest_idx = len(expiration_dates) - 1\n",
    "            \n",
    "        # If the closest date is after the target, look one before\n",
    "        if closest_idx > 0 and (abs((expiration_dates[closest_idx-1] - target_date).days) < \n",
    "                               abs((expiration_dates[closest_idx] - target_date).days)):\n",
    "            closest_idx -= 1\n",
    "        \n",
    "        # Calculate how many dates we can get before the target\n",
    "        available_before = closest_idx\n",
    "        # Calculate how many dates we can get after the target (including the closest)\n",
    "        available_after = len(expiration_dates) - closest_idx\n",
    "        \n",
    "\n",
    "        # Calculate how many we should get from each side\n",
    "        to_take_before = min(available_before, num_expirations)\n",
    "        to_take_after = min(available_after, num_expirations)\n",
    "        \n",
    "        # If we can't get enough from one side, get more from the other side\n",
    "        extra_before = 0\n",
    "        extra_after = 0\n",
    "        \n",
    "        if to_take_before < num_expirations:\n",
    "            # We need to get extra from after side\n",
    "            extra_after = min(available_after - to_take_after, num_expirations - to_take_before)\n",
    "        \n",
    "        if to_take_after < num_expirations:\n",
    "            # We need to get extra from before side\n",
    "            extra_before = min(available_before - to_take_before, num_expirations - to_take_after)\n",
    "            \n",
    "        # Calculate final indices\n",
    "        start_idx = max(0, closest_idx - to_take_before - extra_before)\n",
    "        end_idx = min(len(expiration_dates), closest_idx + to_take_after + extra_after)\n",
    "        \n",
    "        # Get the selected expirations\n",
    "        selected_expirations = all_expirations[start_idx:end_idx]\n",
    "\n",
    "\n",
    "        for expiration in selected_expirations:\n",
    "\n",
    "            options = ticker.option_chain(expiration).calls\n",
    "\n",
    "            options = options[\n",
    "                [\"strike\", \"bid\", \"ask\", \"volume\", \"openInterest\", \"impliedVolatility\"]\n",
    "            ].dropna()\n",
    "\n",
    "            options[\"spread\"] = options[\"ask\"] - options[\"bid\"]\n",
    "            options[\"spreadPct\"] = (\n",
    "                options[\"spread\"] / ((options[\"bid\"] + options[\"ask\"]) / 2)\n",
    "            ) * 100\n",
    "\n",
    "            options = options[\n",
    "                (options[\"bid\"] > 0)\n",
    "                & (options[\"ask\"] > 0)\n",
    "                & (options[\"volume\"] >= min_volume)\n",
    "                & (options[\"openInterest\"] > 0)\n",
    "                & (options[\"spreadPct\"] <= max_spread_pct)\n",
    "            ]\n",
    "\n",
    "            moneyness = options[\"strike\"] / underlying_price\n",
    "            options = options[\n",
    "                (moneyness >= moneyness_range[0]) & (moneyness <= moneyness_range[1])\n",
    "            ]\n",
    "            \n",
    "            options = options[(options[\"impliedVolatility\"] > 0.01) & (options[\"impliedVolatility\"] < 3)]\n",
    "\n",
    "            # Calculate maturity\n",
    "            today = datetime.today().date()\n",
    "            expiration_date = pd.to_datetime(expiration).date()\n",
    "            maturity = (expiration_date - today).days / 365.25\n",
    "\n",
    "            for _, row in options.iterrows():\n",
    "                mid = (row[\"bid\"] + row[\"ask\"]) / 2\n",
    "                result.append(\n",
    "                    {\n",
    "                        \"mid_price\": mid,\n",
    "                        \"ask_price\": row[\"ask\"],\n",
    "                        \"maturity\": maturity,\n",
    "                        \"strike\": row[\"strike\"],\n",
    "                        \"implied_volatility\": row[\"impliedVolatility\"],\n",
    "                        \"volume\": row[\"volume\"],\n",
    "                        \"expiration\": expiration_date,\n",
    "                        \"moneyness\": row[\"strike\"] / underlying_price\n",
    "                    }\n",
    "                )\n",
    "\n",
    "        # Convert the list of dictionaries to a DataFrame\n",
    "        df = pd.DataFrame(result)\n",
    "        \n",
    "        # Sort by expiration and strike\n",
    "        if not df.empty:\n",
    "            df = df.sort_values(['expiration', 'strike'])\n",
    "            \n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Failed to fetch market data: {str(e)}\")\n",
    "    \n",
    "# test the function\n",
    "if __name__ == \"__main__\":\n",
    "    symbol = \"^SPX\"\n",
    "    target_expiration = \"2025-07-31\"\n",
    "    underlying_price = 5525.21\n",
    "    data = get_data_Calibration(symbol, target_expiration, underlying_price)\n",
    "    print(f\"Data shape: {data.shape}\")\n",
    "    print(f\"Columns in data: {data.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b8478f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semi-Analytical Heston Model Results:\n",
      "Call Option Price: 5.1571 USD\n"
     ]
    }
   ],
   "source": [
    "# Global price cache to reuse calculations across iterations\n",
    "PRICE_CACHE = {}\n",
    "\n",
    "@njit(complex128(float64, float64, float64, float64, float64, float64, float64, float64, float64, float64, float64, float64))\n",
    "def heston_cf_core(phi, x, r, T, kappa, rho, volvol, theta, var0, div, b, u):\n",
    "    \"\"\"Core calculations for Heston characteristic function - matches original implementation exactly\"\"\"\n",
    "    a = kappa * theta\n",
    "    rvpj = rho * volvol * phi * complex(0, 1)\n",
    "    \n",
    "    # Use more stable computations for d\n",
    "    daux = (b - rvpj) ** 2 - volvol**2 * (2 * u * phi * complex(0, 1) - phi**2)\n",
    "    d = np.sqrt(daux)\n",
    "    \n",
    "    # Handle g calculation with numerical stability\n",
    "    num = b - rvpj + d\n",
    "    den = b - rvpj - d\n",
    "    \n",
    "    # Avoid division by zero for g\n",
    "    if abs(den) < 1e-15:\n",
    "        g = 0.0\n",
    "    else:\n",
    "        g = num / den\n",
    "    \n",
    "    # Handle exponential carefully to avoid overflow\n",
    "    if np.real(d * T) > 700:\n",
    "        exp_dT = np.inf\n",
    "    else:\n",
    "        exp_dT = np.exp(d * T)\n",
    "    \n",
    "    g_exp_dT = g * exp_dT\n",
    "    \n",
    "    # Safe computation for D\n",
    "    if abs(1.0 - g_exp_dT) < 1e-15:\n",
    "        D = (num / volvol**2) * T\n",
    "    else:\n",
    "        if np.real(d * T) > 700:\n",
    "            exp_term = np.inf\n",
    "        else:\n",
    "            exp_term = np.exp(d * T)\n",
    "        \n",
    "        D = (num / volvol**2) * ((1.0 - exp_term) / (1.0 - g * exp_term))\n",
    "    \n",
    "    # Safe computation for C\n",
    "    if abs(1.0 - g) < 1e-15:\n",
    "        log_term = d * T\n",
    "    else:\n",
    "        if abs(1.0 - g_exp_dT) < 1e-15:\n",
    "            # When denominator is near zero\n",
    "            if np.real(d * T) > 0:\n",
    "                log_term = 700.0  # Large positive number instead of inf\n",
    "            else:\n",
    "                log_term = -700.0  # Large negative number instead of -inf\n",
    "        else:\n",
    "            # More stable logarithm calculation\n",
    "            log_term = np.log((1.0 - g_exp_dT) / (1.0 - g))\n",
    "    \n",
    "    # Final calculation of C\n",
    "    C = (r - div) * phi * T * complex(0, 1) + (a / volvol**2) * ((b - rvpj + d) * T - 2.0 * log_term)\n",
    "    \n",
    "    # Final CF\n",
    "    CF = np.exp(x * phi * complex(0, 1) + C + D * var0)\n",
    "    \n",
    "    return CF\n",
    "\n",
    "def integrand_core(phi, S, K, T, r, kappa, rho, volvol, theta, var0, div, P1P2):\n",
    "    \"\"\"Core calculations for the integrand function\"\"\"\n",
    "    if abs(phi) < 1e-15:\n",
    "        return 0.0\n",
    "    \n",
    "    x = np.log(S)\n",
    "    u = 0.5 if P1P2 == 1 else -0.5\n",
    "    b = kappa - rho * volvol if P1P2 == 1 else kappa\n",
    "    \n",
    "    try:\n",
    "        CF = heston_cf_core(phi, x, r, T, kappa, rho, volvol, theta, var0, div, b, u)\n",
    "        if np.isnan(CF) or np.isinf(CF):\n",
    "            return 0.0\n",
    "        \n",
    "        Output = np.real((np.exp(-phi * np.log(K) * complex(0, 1)) * CF) / (phi * complex(0, 1)))\n",
    "        if np.isnan(Output) or np.isinf(Output):\n",
    "            return 0.0\n",
    "            \n",
    "        return Output\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "def NumIntegration(aLim, bLim, nDiv, S, K, T, r, kappa, rho, volvol, theta, var0, div, P1P2):\n",
    "    \"\"\"Numerical integration using Simpson's rule - matches original implementation\"\"\"\n",
    "    if nDiv % 2 != 0:  # ensure nDiv is even\n",
    "        nDiv += 1\n",
    "    \n",
    "    Delta = (bLim - aLim) / nDiv\n",
    "    EveryX = np.linspace(aLim, bLim, nDiv + 1)\n",
    "    EveryY = np.zeros(nDiv + 1)\n",
    "    \n",
    "    # Calculate function values at each point\n",
    "    for i in range(nDiv + 1):\n",
    "        EveryY[i] = integrand_core(EveryX[i], S, K, T, r, kappa, rho, volvol, theta, var0, div, P1P2)\n",
    "    \n",
    "    # Simpson's rule integration\n",
    "    even_indices = np.arange(2, nDiv, 2)\n",
    "    odd_indices = np.arange(1, nDiv, 2)\n",
    "    \n",
    "    even_sum = np.sum(EveryY[even_indices])\n",
    "    odd_sum = np.sum(EveryY[odd_indices])\n",
    "    \n",
    "    Integral = (Delta/3) * (EveryY[0] + 4*odd_sum + 2*even_sum + EveryY[-1])\n",
    "    \n",
    "    return Integral\n",
    "\n",
    "@functools.lru_cache(maxsize=20000)\n",
    "def P1P2Heston(S, K, T, r, kappa, rho, volvol, theta, var0, div, P1P2):\n",
    "    \"\"\"P1 and P2 calculation with adaptive integration - matches original implementation\"\"\"\n",
    "    cache_key = (S, K, T, r, round(kappa, 6), round(rho, 6), \n",
    "                round(volvol, 6), round(theta, 6), round(var0, 6), \n",
    "                round(div, 6), P1P2)\n",
    "    \n",
    "    if cache_key in PRICE_CACHE:\n",
    "        return PRICE_CACHE[cache_key]\n",
    "    \n",
    "    # Use an appropriate number of points based on maturity\n",
    "    if T < 0.1:  # For very short maturities, we need more points\n",
    "        nDiv = 2000\n",
    "    elif T < 0.5:  # For short maturities\n",
    "        nDiv = 1000\n",
    "    else:  # For longer maturities\n",
    "        nDiv = 500\n",
    "    \n",
    "    # For extreme strikes, use more points\n",
    "    moneyness = S/K\n",
    "    if moneyness < 0.8 or moneyness > 1.2:\n",
    "        nDiv *= 2\n",
    "    \n",
    "    # Use appropriate upper limit\n",
    "    upper_limit = min(100, max(50, 100/T))\n",
    "    \n",
    "    # Perform numerical integration\n",
    "    NumInt = NumIntegration(1e-6, upper_limit, nDiv, S, K, T, r, kappa, rho, volvol, theta, var0, div, P1P2)\n",
    "    \n",
    "    # Check if the result seems reasonable\n",
    "    PP = 0.5 + (1 / np.pi) * NumInt\n",
    "    \n",
    "    # Fall back to quad if result is outside valid range\n",
    "    if PP < 0 or PP > 1 or np.isnan(PP):\n",
    "        try:\n",
    "            integral, _ = quad(integrand_core, 1e-6, upper_limit,\n",
    "                              args=(S, K, T, r, kappa, rho, volvol, theta, var0, div, P1P2),\n",
    "                              limit=100, epsabs=1e-8, epsrel=1e-8)\n",
    "            PP = 0.5 + (1 / np.pi) * integral\n",
    "        except:\n",
    "            PP = 0.5  # Fallback value\n",
    "    \n",
    "    # Make sure result is between 0 and 1\n",
    "    PP = max(0.0, min(1.0, PP))\n",
    "    PRICE_CACHE[cache_key] = PP\n",
    "    return PP\n",
    "\n",
    "@functools.lru_cache(maxsize=10000)\n",
    "def CallHestonCForm_Cached(S, K, T, r, kappa, rho, volvol, theta, var0, div):\n",
    "    \"\"\"Heston call option pricing with dividend - matches original implementation\"\"\"\n",
    "    # Ensure parameters are within valid ranges\n",
    "    kappa = max(0.001, kappa)  # Mean reversion speed must be positive\n",
    "    volvol = max(0.001, volvol)  # Vol of vol must be positive\n",
    "    theta = max(0.0001, theta)  # Long-term variance must be positive\n",
    "    var0 = max(0.0001, var0)    # Initial variance must be positive\n",
    "    rho = max(-0.999, min(0.999, rho))  # Correlation must be between -1 and 1\n",
    "    \n",
    "    # Fast path for very short maturities\n",
    "    if T <= 1e-6:\n",
    "        return max(0, S * np.exp(-div * T) - K * np.exp(-r * T))\n",
    "    \n",
    "    P1 = P1P2Heston(S, K, T, r, kappa, rho, volvol, theta, var0, div, 1)\n",
    "    P2 = P1P2Heston(S, K, T, r, kappa, rho, volvol, theta, var0, div, 2)\n",
    "    \n",
    "    # Option price calculation with checks\n",
    "    CallValue = S * np.exp(-div * T) * P1 - K * np.exp(-r * T) * P2\n",
    "    \n",
    "    # Ensure non-negative option price\n",
    "    return max(0.0, CallValue)\n",
    "\n",
    "def CallHestonCForm(S, K, T, r, kappa, rho, volvol, theta, var0, div):\n",
    "    \"\"\"Heston call option pricing wrapper with global caching\"\"\"\n",
    "    # Check if calculation is already in the global cache\n",
    "    cache_key = (S, K, T, r, round(kappa, 6), round(rho, 6), \n",
    "                round(volvol, 6), round(theta, 6), round(var0, 6), round(div, 6))\n",
    "    \n",
    "    if cache_key in PRICE_CACHE:\n",
    "        return PRICE_CACHE[cache_key]\n",
    "    \n",
    "    result = CallHestonCForm_Cached(S, K, T, r, kappa, rho, volvol, theta, var0, div)\n",
    "    PRICE_CACHE[cache_key] = result\n",
    "    return result\n",
    "\n",
    "def PutHestonCForm(S, K, T, r, kappa, rho, volvol, theta, var0, div):\n",
    "    \"\"\"Put option pricing function using put-call parity\"\"\"\n",
    "    CallValue = CallHestonCForm(S, K, T, r, kappa, rho, volvol, theta, var0, div)\n",
    "    PutValue = CallValue - S * np.exp(-div * T) + K * np.exp(-r * T)\n",
    "    \n",
    "    # Ensure non-negative option price\n",
    "    return max(0.0, PutValue)\n",
    "\n",
    "def clear_cache():\n",
    "    \"\"\"Clear all caches to free memory\"\"\"\n",
    "    global PRICE_CACHE\n",
    "    PRICE_CACHE = {}\n",
    "    P1P2Heston.cache_clear()\n",
    "    CallHestonCForm_Cached.cache_clear()\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Parameters\n",
    "    S = 100         # Initial stock price\n",
    "    K = 101         # Strike price\n",
    "    T = 1           # Time to maturity (years)\n",
    "    r = 0.02        # Risk-free rate\n",
    "    kappa = 1.5     # Mean reversion speed\n",
    "    rho = -0.4      # Correlation\n",
    "    volvol = 0.6    # Volatility of variance\n",
    "    theta = 0.03    # Long-term variance mean\n",
    "    var0 = 0.014    # Initial variance\n",
    "    div = 0.005     # Dividend yield\n",
    "    \n",
    "    # Calculate prices using semi-analytical method\n",
    "    callPrice = CallHestonCForm(S, K, T, r, kappa, rho, volvol, theta, var0, div)\n",
    "    \n",
    "    print(\"Semi-Analytical Heston Model Results:\")\n",
    "    print(f\"Call Option Price: {callPrice:.4f} USD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bb0e4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallel version for batch pricing\n",
    "def heston_prices_parallel(params, Spots, Strikes, Maturities, Rates, div):\n",
    "    \"\"\"Price multiple options in parallel for calibration\"\"\"\n",
    "\n",
    "    results = []\n",
    "    kappa, rho, volvol, theta, var0 = params  # Unpack parameters\n",
    "    \n",
    "    for i in range(len(Spots)):\n",
    "        # Call with proper arguments in correct order\n",
    "        price = CallHestonCForm(Spots[i], Strikes[i], Maturities[i], Rates[i], \n",
    "                               kappa, rho, volvol, theta, var0, div)\n",
    "        results.append(price)\n",
    "        \n",
    "    return np.array(results)\n",
    "\n",
    "\n",
    "def OptFunctionFast(params, Spots, Maturities, Rates, Strikes, MarketP, div, check_bounds=True):\n",
    "    \"\"\"Optimized cost function for faster calibration with early stopping\"\"\"\n",
    "    kappa, rho, volvol, theta, var0 = params\n",
    "    min_price = 1e-6\n",
    "    error_penalty = 1e10\n",
    "    \n",
    "    # Fast boundary check - return early for invalid parameters\n",
    "    if check_bounds and not (\n",
    "            0.1 <= kappa <= 15.0 and \n",
    "            -0.99 <= rho <= 0.0 and \n",
    "            0.01 <= volvol <= 2.0 and \n",
    "            0.001 <= theta <= 0.5 and \n",
    "            0.001 <= var0 <= 0.5):\n",
    "        return error_penalty\n",
    "    \n",
    "    # Filter valid market prices\n",
    "    valid_indices = np.isfinite(MarketP) & (MarketP > 0)\n",
    "    if not np.any(valid_indices):\n",
    "        return error_penalty\n",
    "        \n",
    "    # Use only valid data points\n",
    "    valid_Spots = Spots[valid_indices]\n",
    "    valid_Strikes = Strikes[valid_indices]\n",
    "    valid_Maturities = Maturities[valid_indices]\n",
    "    valid_Rates = Rates[valid_indices]\n",
    "    valid_MarketP = MarketP[valid_indices]\n",
    "    \n",
    "    # Calculate model prices without threading for small datasets\n",
    "    model_prices = heston_prices_parallel(\n",
    "        params, valid_Spots, valid_Strikes, valid_Maturities, valid_Rates, div\n",
    "    )\n",
    "    \n",
    "    # Calculate simple error metric - optimization for speed\n",
    "    abs_errors = np.abs(model_prices - valid_MarketP)\n",
    "    mean_error = np.mean(abs_errors)\n",
    "    \n",
    "    # Check threshold for early stopping - if error is already large, return early\n",
    "    if mean_error > 10.0:  # If average error is $10 or more, skip detailed calculations\n",
    "        return mean_error * 10  # Simple penalty\n",
    "    \n",
    "    # ATM options have higher weights\n",
    "    moneyness = valid_Strikes / valid_Spots\n",
    "    weights = 1.0 + np.exp(-20.0 * (moneyness - 1.0) ** 2)  # Simplified weighting\n",
    "    \n",
    "    # Weighted squared error\n",
    "    weighted_errors = (model_prices - valid_MarketP) ** 2 * weights\n",
    "    mse = np.mean(weighted_errors)\n",
    "    \n",
    "    return mse if np.isfinite(mse) else error_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b882ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_calibrate_heston(\n",
    "    symbol: str,\n",
    "    expiration: str,\n",
    "    underlying_price: float,\n",
    "    risk_free_rate: float,\n",
    "    dividend_yield: float = 0.01,  # Added explicit dividend_yield parameter\n",
    "    max_time_seconds: int = 60,  # Reduced from 120 to 60 seconds\n",
    "):\n",
    "    \"\"\"Fast Heston calibration for small datasets with aggressive optimizations\"\"\"\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        clear_cache()  # Clear cache before starting new calibration\n",
    "        \n",
    "        # Get market data\n",
    "        market_data = get_data_Calibration(symbol, expiration, underlying_price)\n",
    "        \n",
    "        if market_data.empty:\n",
    "            raise ValueError(\"No valid market data available for calibration\")\n",
    "\n",
    "        # Use mid_price for calibration target\n",
    "        MarketP = market_data[\"mid_price\"].values \n",
    "        Strikes = market_data[\"strike\"].values\n",
    "        Maturities = market_data[\"maturity\"].values\n",
    "        Rates = np.full_like(Maturities, risk_free_rate)\n",
    "        Spots = np.full_like(Maturities, underlying_price)\n",
    "\n",
    "        # Filter options data - focus only on valid, liquid options\n",
    "        valid_indices = (MarketP > 0) & (Maturities > 0) & np.isfinite(MarketP)\n",
    "        if not np.any(valid_indices):\n",
    "             raise ValueError(\"No market data points with positive price and maturity.\")\n",
    "             \n",
    "        MarketP = MarketP[valid_indices]\n",
    "        Strikes = Strikes[valid_indices]\n",
    "        Maturities = Maturities[valid_indices]\n",
    "        Rates = Rates[valid_indices]\n",
    "        Spots = Spots[valid_indices]\n",
    "        filtered_market_data = market_data[valid_indices].copy()  # Use copy to avoid SettingWithCopyWarning\n",
    "\n",
    "        # Subsample data if we have too many options for faster calibration\n",
    "        n_options = len(MarketP)\n",
    "        if n_options > 100:  # If more than 50 options, take a representative subset\n",
    "            try:\n",
    "                # Group by moneyness and maturity to get a representative subset\n",
    "                filtered_market_data['moneyness_bin'] = pd.qcut(filtered_market_data['moneyness'], 5, labels=False, duplicates='drop')\n",
    "                filtered_market_data['maturity_bin'] = pd.qcut(filtered_market_data['maturity'], \n",
    "                                                           min(5, len(filtered_market_data['maturity'].unique())), \n",
    "                                                           labels=False, duplicates='drop')\n",
    "                \n",
    "                # Create a stratified sample\n",
    "                grouped = filtered_market_data.groupby(['moneyness_bin', 'maturity_bin'])\n",
    "                sampled_data = pd.DataFrame()\n",
    "                \n",
    "                # Take a few options from each group\n",
    "                for _, group in grouped:\n",
    "                    sample_size = min(3, len(group))  # Take up to 3 from each group\n",
    "                    sampled_data = pd.concat([sampled_data, group.sample(sample_size)])\n",
    "                \n",
    "                if len(sampled_data) > 0:\n",
    "                    filtered_market_data = sampled_data\n",
    "                    MarketP = filtered_market_data[\"mid_price\"].values\n",
    "                    Strikes = filtered_market_data[\"strike\"].values\n",
    "                    Maturities = filtered_market_data[\"maturity\"].values\n",
    "                    Rates = np.full_like(Maturities, risk_free_rate)\n",
    "                    Spots = np.full_like(Maturities, underlying_price)\n",
    "                    print(f\"Reduced from {n_options} to {len(MarketP)} options for faster calibration\")\n",
    "            except Exception as e:\n",
    "                # Fallback to simple random sampling if quantile binning fails\n",
    "                print(f\"Stratified sampling failed: {e}. Using random sampling instead.\")\n",
    "                sample_size = min(50, n_options)\n",
    "                sampled_indices = np.random.choice(n_options, size=sample_size, replace=False)\n",
    "                filtered_market_data = filtered_market_data.iloc[sampled_indices]\n",
    "                MarketP = filtered_market_data[\"mid_price\"].values\n",
    "                Strikes = filtered_market_data[\"strike\"].values\n",
    "                Maturities = filtered_market_data[\"maturity\"].values\n",
    "                Rates = np.full_like(Maturities, risk_free_rate)\n",
    "                Spots = np.full_like(Maturities, underlying_price)\n",
    "                print(f\"Reduced from {n_options} to {len(MarketP)} options using random sampling\")\n",
    "\n",
    "        # Smart initial estimate based on market data\n",
    "        avg_iv = np.mean(filtered_market_data[\"implied_volatility\"])\n",
    "        var0 = avg_iv ** 2\n",
    "        theta = var0\n",
    "        kappa = 1.5\n",
    "        volvol = 0.3 * avg_iv  # Proportional to avg IV\n",
    "        rho = -0.7\n",
    "        \n",
    "        # Multiple initial guesses for better convergence\n",
    "        initial_guesses = [\n",
    "            [kappa, rho, volvol, theta, var0],  # Base guess\n",
    "            [3.0, -0.5, 0.5, theta, var0],      # Alternative 1\n",
    "            [1.0, -0.8, 0.2, theta, var0]       # Alternative 2\n",
    "        ]\n",
    "        \n",
    "        # Parameter bounds - tighter for faster convergence\n",
    "        bounds = [\n",
    "            (0.1, 10.0),     # kappa: reduced upper bound\n",
    "            (-0.95, 0.0),    # rho: typically negative for equity\n",
    "            (0.01, 1.5),     # volvol: reduced upper bound\n",
    "            (0.001, 0.4),    # theta: tighter range\n",
    "            (0.001, 0.4)     # var0: tighter range\n",
    "        ]\n",
    "        \n",
    "        # Optimization setup with dividend yield parameter\n",
    "        opt_args = (Spots, Maturities, Rates, Strikes, MarketP, dividend_yield, True)\n",
    "        best_result = None\n",
    "        best_error = float('inf')\n",
    "        \n",
    "        # Try different initial guesses with a fast local search\n",
    "        for x0 in initial_guesses:\n",
    "            # Check time budget\n",
    "            if time.time() - start_time > max_time_seconds:\n",
    "                print(f\"Time limit reached after trying {initial_guesses.index(x0)} initial points\")\n",
    "                break\n",
    "                \n",
    "            # Fast optimization with limited iterations\n",
    "            try:\n",
    "                result = minimize(\n",
    "                    OptFunctionFast,\n",
    "                    x0,\n",
    "                    method=\"L-BFGS-B\",\n",
    "                    bounds=bounds,\n",
    "                    args=opt_args,\n",
    "                    options={\n",
    "                        \"maxiter\": 50,     # Reduced from 200 to 50\n",
    "                        \"maxfun\": 100,    # Limit function evaluations\n",
    "                        \"disp\": False,\n",
    "                        \"ftol\": 1e-6,     # Reduced precision\n",
    "                        \"gtol\": 1e-5      # Reduced precision\n",
    "                    }\n",
    "                )\n",
    "                \n",
    "                # Check if this result is better than previous ones\n",
    "                if result.fun < best_error:\n",
    "                    best_result = result\n",
    "                    best_error = result.fun\n",
    "            except Exception as e:\n",
    "                print(f\"Optimization failed for initial guess {x0}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # If we have no valid result, try one more time with Nelder-Mead (more robust)\n",
    "        if best_result is None:\n",
    "            try:\n",
    "                # Nelder-Mead doesn't use bounds but is more robust\n",
    "                result = minimize(\n",
    "                    lambda p: OptFunctionFast(p, Spots, Maturities, Rates, Strikes, MarketP, dividend_yield, False),\n",
    "                    initial_guesses[0],\n",
    "                    method=\"Nelder-Mead\",\n",
    "                    options={\n",
    "                        \"maxiter\": 100,\n",
    "                        \"maxfev\": 200,\n",
    "                        \"disp\": False,\n",
    "                        \"adaptive\": True\n",
    "                    }\n",
    "                )\n",
    "                best_result = result\n",
    "            except Exception as e:\n",
    "                raise ValueError(f\"All optimization attempts failed: {e}\")\n",
    "        \n",
    "        # Extract calibrated parameters\n",
    "        calibrated_params = {\n",
    "            \"kappa\": float(best_result.x[0]),\n",
    "            \"rho\": float(best_result.x[1]),\n",
    "            \"volvol\": float(best_result.x[2]),\n",
    "            \"theta\": float(best_result.x[3]),\n",
    "            \"var0\": float(best_result.x[4])\n",
    "        }\n",
    "        \n",
    "        # Evaluate model prices with calibrated parameters\n",
    "        model_prices = heston_prices_parallel(\n",
    "            (calibrated_params[\"kappa\"], calibrated_params[\"rho\"], \n",
    "             calibrated_params[\"volvol\"], calibrated_params[\"theta\"], calibrated_params[\"var0\"]),\n",
    "            Spots, Strikes, Maturities, Rates, dividend_yield  # Added dividend_yield\n",
    "        )\n",
    "        \n",
    "        # Calculate error metrics using the full dataset (not just the sample)\n",
    "        valid_model_prices = np.isfinite(model_prices) & (model_prices > 0)\n",
    "        MarketP_valid = MarketP[valid_model_prices]\n",
    "        model_prices_valid = model_prices[valid_model_prices]\n",
    "        filtered_market_data_valid = filtered_market_data.iloc[valid_model_prices]\n",
    "        \n",
    "        if len(MarketP_valid) == 0:\n",
    "            raise ValueError(\"No valid model prices could be calculated with calibrated parameters.\")\n",
    "\n",
    "        # Calculate basic error metrics\n",
    "        errors = model_prices_valid - MarketP_valid\n",
    "        relative_errors_pct = (errors / MarketP_valid) * 100\n",
    "        mse = np.mean(errors**2)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = np.mean(np.abs(errors))\n",
    "        total_time = time.time() - start_time\n",
    "\n",
    "        return {\n",
    "            \"success\": best_result.success if hasattr(best_result, 'success') else True,\n",
    "            \"kappa\": float(calibrated_params[\"kappa\"]),\n",
    "            \"theta\": float(calibrated_params[\"theta\"]),\n",
    "            \"volvol\": float(calibrated_params[\"volvol\"]),\n",
    "            \"rho\": float(calibrated_params[\"rho\"]),\n",
    "            \"var0\": float(calibrated_params[\"var0\"]),\n",
    "            \"div\": float(dividend_yield),  # Include div in result\n",
    "            \"calibration_metrics\": {\n",
    "                \"MSE\": mse,\n",
    "                \"RMSE\": rmse,\n",
    "                \"MAE\": mae,\n",
    "                \"max_abs_error\": np.max(np.abs(errors)),\n",
    "                \"mean_rel_error_pct\": np.mean(np.abs(relative_errors_pct)),\n",
    "                \"median_rel_error_pct\": np.median(np.abs(relative_errors_pct)),\n",
    "                \"n_options_used\": len(MarketP_valid),\n",
    "                \"original_n_options\": n_options,\n",
    "                \"optimizer_iterations\": best_result.nit if hasattr(best_result, 'nit') else best_result.nfev,\n",
    "                \"calibration_time_seconds\": total_time\n",
    "            },\n",
    "            \"market_data_used\": filtered_market_data_valid.to_dict(orient=\"records\")\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        return {\n",
    "            \"success\": False,\n",
    "            \"error\": str(e),\n",
    "            \"error_details\": traceback.format_exc(),\n",
    "            \"kappa\": 0.0,\n",
    "            \"theta\": 0.0,\n",
    "            \"volvol\": 0.0,\n",
    "            \"rho\": 0.0,\n",
    "            \"var0\": 0.0,\n",
    "            \"div\": float(dividend_yield),\n",
    "            \"calibration_time_seconds\": time.time() - start_time\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "484cb1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fast calibration for ^SPX...\n",
      "Target: 2025-07-31, S0: $5525.21, r: 4.00%, div: 1.00%\n",
      "Reduced from 1020 to 75 options for faster calibration\n",
      "\n",
      "Calibration completed in 9.77 seconds\n",
      "\n",
      "Calibration Results:\n",
      "===================\n",
      "\n",
      "Calibrated Heston Parameters:\n",
      "  κ (kappa)  = 3.0000  - Mean reversion rate\n",
      "  θ (theta)  = 0.0546  - Long-term variance\n",
      "  σ (volvol) = 0.5000  - Volatility of variance\n",
      "  ρ (rho)    = -0.5000  - Correlation\n",
      "  v₀ (var0)  = 0.0546  - Initial variance\n",
      "  δ (div)    = 0.0100  - Dividend yield\n",
      "  Long-term volatility = 23.37%\n",
      "  Initial volatility   = 23.37%\n",
      "\n",
      "Calibration Metrics:\n",
      "  Data sample: 75 of 1020 options\n",
      "  RMSE: 65.2496\n",
      "  MAE: 28.5796\n",
      "  Max Error: $517.48\n",
      "  Mean Relative Error: 39.69%\n",
      "\n",
      "Feller Condition: 0.0777 (satisfied)\n"
     ]
    }
   ],
   "source": [
    "# Test the ultra-fast calibration function\n",
    "symbol = '^SPX'  # Example symbol\n",
    "target_expiration = '2025-07-31'  # Example target expiration\n",
    "underlying_price = 5525.21  # Example underlying price\n",
    "risk_free_rate = 0.04  # Example risk-free rate (e.g., 4%)\n",
    "dividend_yield = 0.01  # Example dividend yield (e.g., 1%)\n",
    "\n",
    "print(f\"Starting fast calibration for {symbol}...\")\n",
    "print(f\"Target: {target_expiration}, S0: ${underlying_price:.2f}, r: {risk_free_rate:.2%}, div: {dividend_yield:.2%}\")\n",
    "\n",
    "# Use a timer to measure calibration speed\n",
    "t0 = time.time()\n",
    "\n",
    "calibration_results = fast_calibrate_heston(\n",
    "    symbol,\n",
    "    target_expiration,\n",
    "    underlying_price,\n",
    "    risk_free_rate,\n",
    "    dividend_yield,  # Added dividend yield parameter\n",
    "    max_time_seconds=60  # Force completion within 60 seconds\n",
    ")\n",
    "\n",
    "calibration_time = time.time() - t0\n",
    "print(f\"\\nCalibration completed in {calibration_time:.2f} seconds\")\n",
    "\n",
    "if calibration_results['success']:\n",
    "    print(\"\\nCalibration Results:\")\n",
    "    print(\"===================\")\n",
    "    \n",
    "    print(\"\\nCalibrated Heston Parameters:\")\n",
    "    print(f\"  κ (kappa)  = {calibration_results['kappa']:.4f}  - Mean reversion rate\")\n",
    "    print(f\"  θ (theta)  = {calibration_results['theta']:.4f}  - Long-term variance\")\n",
    "    print(f\"  σ (volvol) = {calibration_results['volvol']:.4f}  - Volatility of variance\")\n",
    "    print(f\"  ρ (rho)    = {calibration_results['rho']:.4f}  - Correlation\")\n",
    "    print(f\"  v₀ (var0)  = {calibration_results['var0']:.4f}  - Initial variance\")\n",
    "    print(f\"  δ (div)    = {calibration_results['div']:.4f}  - Dividend yield\")\n",
    "    \n",
    "    # Calculate volatilities\n",
    "    print(f\"  Long-term volatility = {np.sqrt(calibration_results['theta']):.2%}\")\n",
    "    print(f\"  Initial volatility   = {np.sqrt(calibration_results['var0']):.2%}\")\n",
    "    \n",
    "    print(\"\\nCalibration Metrics:\")\n",
    "    metrics = calibration_results['calibration_metrics']\n",
    "    if 'original_n_options' in metrics and metrics['original_n_options'] != metrics['n_options_used']:\n",
    "        print(f\"  Data sample: {metrics['n_options_used']} of {metrics['original_n_options']} options\")\n",
    "    else:\n",
    "        print(f\"  Options used: {metrics.get('n_options_used', 'N/A')}\")\n",
    "        \n",
    "    print(f\"  RMSE: {metrics['RMSE']:.4f}\")\n",
    "    print(f\"  MAE: {metrics['MAE']:.4f}\")\n",
    "    print(f\"  Max Error: ${metrics.get('max_abs_error', 'N/A'):.2f}\")\n",
    "    print(f\"  Mean Relative Error: {metrics.get('mean_rel_error_pct', 'N/A'):.2f}%\")\n",
    "    \n",
    "    # Check Feller condition\n",
    "    feller = 2 * calibration_results['kappa'] * calibration_results['theta'] - calibration_results['volvol']**2\n",
    "    print(f\"\\nFeller Condition: {feller:.4f} {'(satisfied)' if feller > 0 else '(violated)'}\")\n",
    "else:\n",
    "    print(\"\\nCalibration Failed.\")\n",
    "    print(f\"Error: {calibration_results.get('error', 'Unknown error')}\")\n",
    "    if 'error_details' in calibration_results:\n",
    "        print(\"\\nError Details:\")\n",
    "        print(calibration_results['error_details'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb8221f",
   "metadata": {},
   "source": [
    "## Performance Optimization Notes\n",
    "\n",
    "The fast calibration implementation includes several key optimizations:\n",
    "\n",
    "1. **Reduced Integration Points**: Using fewer Gauss-Laguerre quadrature points (16 instead of 48)\n",
    "\n",
    "2. **Multi-level Caching**: \n",
    "   - LRU cache for characteristic function\n",
    "   - LRU cache for option pricing\n",
    "   - Global dictionary cache to avoid repeated calculations\n",
    "\n",
    "3. **Fast Approximations**:\n",
    "   - Black-Scholes approximation for low volatility of volatility\n",
    "   - Early exit for deep OTM or extreme-strike options\n",
    "\n",
    "4. **Optimization Strategy**:\n",
    "   - Multiple starting points instead of global optimization\n",
    "   - Limited iterations and function evaluations\n",
    "   - Early stopping when error is already large\n",
    "\n",
    "5. **Data Sampling**:\n",
    "   - For larger datasets, uses a stratified sample of options\n",
    "   - Ensures representation across moneyness and maturities\n",
    "   \n",
    "6. **Simplified Error Calculation**:\n",
    "   - Fast weighted error calculation\n",
    "   - Early exit for obviously poor parameter sets\n",
    "\n",
    "These optimizations significantly reduce the calibration time while maintaining reasonable accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
